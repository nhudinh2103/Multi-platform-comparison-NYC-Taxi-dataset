{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# What's in this exercise?\n",
        "\n",
        "1) Read raw data, augment with derived attributes, augment with reference data & persist<BR> \n",
        "2) Create external unmanaged Hive tables<BR>\n",
        "3) Create statistics for tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType,LongType,FloatType,DoubleType, TimestampType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.  Execute notebook with common/reusable functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Code from file 'file:///home/dinhnn/git/personal/Databricks-NYC-Taxi/Workspace/01-General/2-CommonFunctions.ipynb':\n",
              " import os\n",
              "import math\n",
              "import glob\n",
              "import re\n",
              "prqShrinkageFactor = 0.19 #We found a saving in space of 81% with Parquet\n",
              "def analyzeTables(databaseAndTable):\n",
              "  try:\n",
              "    print(\"Table: \" + databaseAndTable)\n",
              "    print(\"....refresh table\")\n",
              "    sql(\"REFRESH TABLE \" + databaseAndTable)\n",
              "    print(\"....analyze table\")\n",
              "    sql(\"ANALYZE TABLE \" + databaseAndTable + \" COMPUTE STATISTICS\")\n",
              "    print(\"....done\")\n",
              "  except Exception as e:\n",
              "    return e\n",
              "def calcOutputFileCountTxtToPrq(srcDataFile, targetedFileSizeMB):\n",
              "  try:\n",
              "    estFileCount = int(math.floor((os.path.getsize(srcDataFile) * prqShrinkageFactor) / (targetedFileSizeMB * 1024 * 1024)))\n",
              "    if(estFileCount == 0):\n",
              "      return 1 \n",
              "    else:\n",
              "      return estFileCount\n",
              "  except Exception as e:\n",
              "    return e\n",
              "#Delete residual files from job operation (_SUCCESS, _start*, _committed*)\n",
              "#Should be called with '/dbfs/mnt/...'\n",
              "def recursivelyDeleteSparkJobFlagFiles(directoryPath):\n",
              "  try:\n",
              "    files = glob.glob(directoryPath + '/**/*', recursive=True)\n",
              "    for file in files:\n",
              "      if not os.path.basename(file).endswith('parquet') and os.path.isfile(file):\n",
              "        fileReplaced = re.sub('/dbfs', 'dbfs:',file)\n",
              "        print(\"Deleting....\" +  fileReplaced)\n",
              "        dbutils.fs.rm(fileReplaced)\n",
              "  except Exception as e:\n",
              "    return e"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "%run \"../../../../01-General/2-CommonFunctions.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.  Read raw, augment, persist as parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "# Non optimized\n",
        "\n",
        "# curatedDF = sql(\"\"\"\n",
        "#   select distinct t.taxi_type,\n",
        "#       t.vendor_id as vendor_id,\n",
        "#       t.pickup_datetime,\n",
        "#       t.dropoff_datetime,\n",
        "#       t.store_and_fwd_flag,\n",
        "#       t.rate_code_id,\n",
        "#       t.pickup_location_id,\n",
        "#       t.dropoff_location_id,\n",
        "#       t.pickup_longitude,\n",
        "#       t.pickup_latitude,\n",
        "#       t.dropoff_longitude,\n",
        "#       t.dropoff_latitude,\n",
        "#       t.passenger_count,\n",
        "#       t.trip_distance,\n",
        "#       t.fare_amount,\n",
        "#       t.extra,\n",
        "#       t.mta_tax,\n",
        "#       t.tip_amount,\n",
        "#       t.tolls_amount,\n",
        "#       t.improvement_surcharge,\n",
        "#       t.total_amount,\n",
        "#       t.payment_type,\n",
        "#       t.trip_year,\n",
        "#       t.trip_month,\n",
        "#       v.abbreviation as vendor_abbreviation,\n",
        "#       v.description as vendor_description,\n",
        "#       tm.month_name_short,\n",
        "#       tm.month_name_full,\n",
        "#       pt.description as payment_type_description,\n",
        "#       rc.description as rate_code_description,\n",
        "#       tzpu.borough as pickup_borough,\n",
        "#       tzpu.zone as pickup_zone,\n",
        "#       tzpu.service_zone as pickup_service_zone,\n",
        "#       tzdo.borough as dropoff_borough,\n",
        "#       tzdo.zone as dropoff_zone,\n",
        "#       tzdo.service_zone as dropoff_service_zone,\n",
        "#       year(t.pickup_datetime) as pickup_year,\n",
        "#       month(t.pickup_datetime) as pickup_month,\n",
        "#       day(t.pickup_datetime) as pickup_day,\n",
        "#       hour(t.pickup_datetime) as pickup_hour,\n",
        "#       minute(t.pickup_datetime) as pickup_minute,\n",
        "#       second(t.pickup_datetime) as pickup_second,\n",
        "#       date(t.pickup_datetime) as pickup_date,\n",
        "#       year(t.dropoff_datetime) as dropoff_year,\n",
        "#       month(t.dropoff_datetime) as dropoff_month,\n",
        "#       day(t.dropoff_datetime) as dropoff_day,\n",
        "#       hour(t.dropoff_datetime) as dropoff_hour,\n",
        "#       minute(t.dropoff_datetime) as dropoff_minute,\n",
        "#       second(t.dropoff_datetime) as dropoff_second,\n",
        "#       date(t.dropoff_datetime) as dropoff_date\n",
        "#   from \n",
        "#     `synapse_nyc_reference`.`nyctaxi`.`yellow_taxi_trips_raw` t\n",
        "#     left join `synapse_nyc_reference`.`nyctaxi`.vendor_lookup v \n",
        "#       on (t.vendor_id = v.abbreviation)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.trip_month_lookup tm \n",
        "#       on (t.trip_month = tm.trip_month)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.payment_type_lookup pt \n",
        "#       on (t.payment_type = pt.abbreviation)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.rate_code_lookup rc \n",
        "#       on (t.rate_code_id = rc.rate_code_id)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzpu \n",
        "#       on (t.pickup_location_id = tzpu.location_id)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzdo \n",
        "#       on (t.dropoff_location_id = tzdo.location_id)\n",
        "# WHERE t.trip_year < 2015\n",
        "# UNION ALL\n",
        "#   select distinct t.taxi_type,\n",
        "#       t.vendor_id as vendor_id,\n",
        "#       t.pickup_datetime,\n",
        "#       t.dropoff_datetime,\n",
        "#       t.store_and_fwd_flag,\n",
        "#       t.rate_code_id,\n",
        "#       t.pickup_location_id,\n",
        "#       t.dropoff_location_id,\n",
        "#       t.pickup_longitude,\n",
        "#       t.pickup_latitude,\n",
        "#       t.dropoff_longitude,\n",
        "#       t.dropoff_latitude,\n",
        "#       t.passenger_count,\n",
        "#       t.trip_distance,\n",
        "#       t.fare_amount,\n",
        "#       t.extra,\n",
        "#       t.mta_tax,\n",
        "#       t.tip_amount,\n",
        "#       t.tolls_amount,\n",
        "#       t.improvement_surcharge,\n",
        "#       t.total_amount,\n",
        "#       t.payment_type,\n",
        "#       t.trip_year,\n",
        "#       t.trip_month,\n",
        "#       v.abbreviation as vendor_abbreviation,\n",
        "#       v.description as vendor_description,\n",
        "#       tm.month_name_short,\n",
        "#       tm.month_name_full,\n",
        "#       pt.description as payment_type_description,\n",
        "#       rc.description as rate_code_description,\n",
        "#       tzpu.borough as pickup_borough,\n",
        "#       tzpu.zone as pickup_zone,\n",
        "#       tzpu.service_zone as pickup_service_zone,\n",
        "#       tzdo.borough as dropoff_borough,\n",
        "#       tzdo.zone as dropoff_zone,\n",
        "#       tzdo.service_zone as dropoff_service_zone,\n",
        "#       year(t.pickup_datetime) as pickup_year,\n",
        "#       month(t.pickup_datetime) as pickup_month,\n",
        "#       day(t.pickup_datetime) as pickup_day,\n",
        "#       hour(t.pickup_datetime) as pickup_hour,\n",
        "#       minute(t.pickup_datetime) as pickup_minute,\n",
        "#       second(t.pickup_datetime) as pickup_second,\n",
        "#       date(t.pickup_datetime) as pickup_date,\n",
        "#       year(t.dropoff_datetime) as dropoff_year,\n",
        "#       month(t.dropoff_datetime) as dropoff_month,\n",
        "#       day(t.dropoff_datetime) as dropoff_day,\n",
        "#       hour(t.dropoff_datetime) as dropoff_hour,\n",
        "#       minute(t.dropoff_datetime) as dropoff_minute,\n",
        "#       second(t.dropoff_datetime) as dropoff_second,\n",
        "#       date(t.dropoff_datetime) as dropoff_date\n",
        "#   from \n",
        "#     `synapse_nyc_reference`.`nyctaxi`.`yellow_taxi_trips_raw` t\n",
        "#     left join `synapse_nyc_reference`.`nyctaxi`.vendor_lookup v \n",
        "#       on (t.vendor_id = v.vendor_id)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.trip_month_lookup tm \n",
        "#       on (t.trip_month = tm.trip_month)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.payment_type_lookup pt \n",
        "#       on (t.payment_type = pt.payment_type)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.rate_code_lookup rc \n",
        "#       on (t.rate_code_id = rc.rate_code_id)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzpu \n",
        "#       on (t.pickup_location_id = tzpu.location_id)\n",
        "#     left join  `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzdo \n",
        "#       on (t.dropoff_location_id = tzdo.location_id)\n",
        "# WHERE t.trip_year >= 2015\n",
        "#   \"\"\")\n",
        "\n",
        "# curatedDFConformed = (curatedDF.withColumn(\"temp_vendor_id\", col(\"vendor_id\").cast(\"integer\")).drop(\"vendor_id\").withColumnRenamed(\"temp_vendor_id\", \"vendor_id\").withColumn(\"temp_payment_type\", col(\"payment_type\").cast(\"integer\")).drop(\"payment_type\").withColumnRenamed(\"temp_payment_type\", \"payment_type\"))\n",
        "\n",
        "#Save as parquet, partition by year and month\n",
        "#curatedDFConformed.coalesce(15).write.partitionBy(\"trip_year\", \"trip_month\").parquet(destDataDirRoot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "id": "dcf3a744",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "DATABRICKS_HOST = dbutils.secrets.get(scope=\"databricks-warehouse\", key=\"sql-host\").replace(\"https://\", \"\")\n",
        "DATABRICKS_HTTP_PATH = f\"/sql/1.0/warehouses/{dbutils.secrets.get(scope=\"databricks-warehouse\", key=\"warehouseid\")}\"\n",
        "DATABRICKS_TOKEN = dbutils.secrets.get(scope=\"databricks-warehouse\", key=\"sql-token\")\n",
        "\n",
        "# JDBC connection URL for Databricks\n",
        "databricks_jdbc_url = f\"jdbc:databricks://{DATABRICKS_HOST}:443;transportMode=http;ssl=1;httpPath={DATABRICKS_HTTP_PATH};AuthMech=3;UID=token;PWD={DATABRICKS_TOKEN}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "id": "74fe5fbd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "destDataDirRoot = f\"gs://nyctaxi-silver/nyctaxi/transform/yellow-taxi/\" #Root dir for consumable data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "id": "90f751eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "# Get the main fact table with optimized reading strategy using Databricks JDBC with a single partition key\n",
        "def optimized_jdbc_read(sql: str = \"\", table: str = \"\", partition_filter: str = \"\", partition_column: str = \"\", num_partitions=200, jdbc_url=databricks_jdbc_url):\n",
        "    \"\"\"\n",
        "    Read a table from Databricks using JDBC with optimized settings and a single partition key\n",
        "    \n",
        "    Args:\n",
        "        table: Full table name including catalog and schema (e.g., \"catalog.schema.table\") or temp table sql (for generate partition id column)\n",
        "        needed_columns: List of columns to select (None for all)\n",
        "        partition_filter: SQL filter expression for partition pruning\n",
        "        partition_keys: List of column names to use for partitioning (only the first one will be used)\n",
        "        num_partitions: Number of partitions to use (default: 200)\n",
        "        jdbc_url: JDBC connection URL for Databricks\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with optimized reading settings\n",
        "        \n",
        "    Raises:\n",
        "        ValueError: If multiple partition keys are provided\n",
        "    \"\"\"\n",
        "    # Define JDBC connection properties\n",
        "    jdbc_properties = {\n",
        "        \"driver\": \"com.databricks.client.jdbc.Driver\",\n",
        "        \"fetchsize\": \"1000000\"  # Fetch size for better performance\n",
        "    }\n",
        "    \n",
        "    # com.databricks.client.jdbc.Driver\n",
        "    \n",
        "    # If no partition keys provided, use default approach\n",
        "    if not partition_column:\n",
        "      return spark.read.format(\"jdbc\") \\\n",
        "                          .option(\"driver\", \"com.databricks.client.jdbc.Driver\") \\\n",
        "                          .option(\"url\", jdbc_url) \\\n",
        "                          .option(\"dbtable\", f\"({sql}) as trip_data\") \\\n",
        "                          .option(\"fetchsize\", \"1000000\") \\\n",
        "                          .load()\n",
        "    \n",
        "    # Get min and max values for the partition column\n",
        "    min_max_query = f\"SELECT MIN({partition_column}) as min_val, MAX({partition_column}) as max_val FROM {f\"({table})\" if \"select\" in table.lower() else table}\"\n",
        "    if partition_filter:\n",
        "        min_max_query += f\" WHERE {partition_filter}\"\n",
        "        \n",
        "    # Execute query to get bounds\n",
        "    bounds_df = spark.read.format(\"jdbc\") \\\n",
        "                          .option(\"driver\", \"com.databricks.client.jdbc.Driver\") \\\n",
        "                          .option(\"url\", jdbc_url) \\\n",
        "                          .option(\"dbtable\", f\"({min_max_query}) as min_max_bounds\") \\\n",
        "                          .option(\"fetchsize\", \"1000000\") \\\n",
        "                          .load()\n",
        "    \n",
        "    # Extract bounds\n",
        "    bounds_row = bounds_df.first()\n",
        "    lower_bound = bounds_row[\"min_val\"]\n",
        "    upper_bound = bounds_row[\"max_val\"]\n",
        "    \n",
        "    # Ensure valid bounds (avoid division by zero)\n",
        "    if lower_bound == upper_bound:\n",
        "        upper_bound = lower_bound + 1\n",
        "    \n",
        "    # Read with numeric partitioning\n",
        "    return spark.read.format(\"jdbc\") \\\n",
        "                     .option(\"driver\", \"com.databricks.client.jdbc.Driver\") \\\n",
        "                     .option(\"url\", jdbc_url) \\\n",
        "                     .option(\"dbtable\", f\"({sql}) as tmp\") \\\n",
        "                     .option(\"numPartitions\", num_partitions) \\\n",
        "                     .option(\"partitionColumn\", partition_column) \\\n",
        "                     .option(\"lowerBound\", lower_bound) \\\n",
        "                     .option(\"upperBound\", upper_bound) \\\n",
        "                     .option(\"fetchsize\", \"100000\") \\\n",
        "                     .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "id": "590de4e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "yellow_taxi_transform_sql = \"\"\"\n",
        "\n",
        "SELECT /*+ BROADCAST(v), BROADCAST(tm), BROADCAST(pt), BROADCAST(rc), BROADCAST(tzpu), BROADCAST(tzdo) */ DISTINCT\n",
        "  t.taxi_type,\n",
        "  t.vendor_id,\n",
        "  t.pickup_datetime,\n",
        "  t.dropoff_datetime,\n",
        "  t.store_and_fwd_flag,\n",
        "  t.rate_code_id,\n",
        "  t.pickup_location_id,\n",
        "  t.dropoff_location_id,\n",
        "  t.pickup_longitude,\n",
        "  t.pickup_latitude,\n",
        "  t.dropoff_longitude,\n",
        "  t.dropoff_latitude,\n",
        "  t.passenger_count,\n",
        "  t.trip_distance,\n",
        "  t.fare_amount,\n",
        "  t.extra,\n",
        "  t.mta_tax,\n",
        "  t.tip_amount,\n",
        "  t.tolls_amount,\n",
        "  t.improvement_surcharge,\n",
        "  t.total_amount,\n",
        "  t.payment_type,\n",
        "  t.trip_year,\n",
        "  t.trip_month,\n",
        "  v.abbreviation AS vendor_abbreviation,\n",
        "  v.description AS vendor_description,\n",
        "  tm.month_name_short,\n",
        "  tm.month_name_full,\n",
        "  pt.description AS payment_type_description,\n",
        "  rc.description AS rate_code_description,\n",
        "  tzpu.borough AS pickup_borough,\n",
        "  tzpu.zone AS pickup_zone,\n",
        "  tzpu.service_zone AS pickup_service_zone,\n",
        "  tzdo.borough AS dropoff_borough,\n",
        "  tzdo.zone AS dropoff_zone,\n",
        "  tzdo.service_zone AS dropoff_service_zone,\n",
        "  year(t.pickup_datetime) AS pickup_year,\n",
        "  month(t.pickup_datetime) AS pickup_month,\n",
        "  day(t.pickup_datetime) AS pickup_day,\n",
        "  hour(t.pickup_datetime) AS pickup_hour,\n",
        "  minute(t.pickup_datetime) AS pickup_minute,\n",
        "  second(t.pickup_datetime) AS pickup_second,\n",
        "  date(t.pickup_datetime) AS pickup_date,\n",
        "  year(t.dropoff_datetime) AS dropoff_year,\n",
        "  month(t.dropoff_datetime) AS dropoff_month,\n",
        "  day(t.dropoff_datetime) AS dropoff_day,\n",
        "  hour(t.dropoff_datetime) AS dropoff_hour,\n",
        "  minute(t.dropoff_datetime) AS dropoff_minute,\n",
        "  second(t.dropoff_datetime) AS dropoff_second,\n",
        "  date(t.dropoff_datetime) AS dropoff_date,\n",
        "  unix_millis(t.pickup_datetime) as partition_id\n",
        "FROM \n",
        "  `synapse_nyc_reference`.`nyctaxi`.yellow_taxi_trips_raw t\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.vendor_lookup v\n",
        "    ON (t.vendor_id = v.abbreviation)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.trip_month_lookup tm\n",
        "    ON (t.trip_month = tm.trip_month)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.payment_type_lookup pt\n",
        "    ON (t.payment_type = pt.abbreviation)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.rate_code_lookup rc\n",
        "    ON (t.rate_code_id = rc.rate_code_id)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzpu\n",
        "    ON (t.pickup_location_id = tzpu.location_id)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzdo\n",
        "    ON (t.dropoff_location_id = tzdo.location_id)\n",
        "WHERE\n",
        "  t.trip_year < 2015\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "SELECT /*+ BROADCAST(v), BROADCAST(tm), BROADCAST(pt), BROADCAST(rc), BROADCAST(tzpu), BROADCAST(tzdo) */ DISTINCT\n",
        "  t.taxi_type,\n",
        "  t.vendor_id,\n",
        "  t.pickup_datetime,\n",
        "  t.dropoff_datetime,\n",
        "  t.store_and_fwd_flag,\n",
        "  t.rate_code_id,\n",
        "  t.pickup_location_id,\n",
        "  t.dropoff_location_id,\n",
        "  t.pickup_longitude,\n",
        "  t.pickup_latitude,\n",
        "  t.dropoff_longitude,\n",
        "  t.dropoff_latitude,\n",
        "  t.passenger_count,\n",
        "  t.trip_distance,\n",
        "  t.fare_amount,\n",
        "  t.extra,\n",
        "  t.mta_tax,\n",
        "  t.tip_amount,\n",
        "  t.tolls_amount,\n",
        "  t.improvement_surcharge,\n",
        "  t.total_amount,\n",
        "  t.payment_type,\n",
        "  t.trip_year,\n",
        "  t.trip_month,\n",
        "  v.abbreviation AS vendor_abbreviation,\n",
        "  v.description AS vendor_description,\n",
        "  tm.month_name_short,\n",
        "  tm.month_name_full,\n",
        "  pt.description AS payment_type_description,\n",
        "  rc.description AS rate_code_description,\n",
        "  tzpu.borough AS pickup_borough,\n",
        "  tzpu.zone AS pickup_zone,\n",
        "  tzpu.service_zone AS pickup_service_zone,\n",
        "  tzdo.borough AS dropoff_borough,\n",
        "  tzdo.zone AS dropoff_zone,\n",
        "  tzdo.service_zone AS dropoff_service_zone,\n",
        "  year(t.pickup_datetime) AS pickup_year,\n",
        "  month(t.pickup_datetime) AS pickup_month,\n",
        "  day(t.pickup_datetime) AS pickup_day,\n",
        "  hour(t.pickup_datetime) AS pickup_hour,\n",
        "  minute(t.pickup_datetime) AS pickup_minute,\n",
        "  second(t.pickup_datetime) AS pickup_second,\n",
        "  date(t.pickup_datetime) AS pickup_date,\n",
        "  year(t.dropoff_datetime) AS dropoff_year,\n",
        "  month(t.dropoff_datetime) AS dropoff_month,\n",
        "  day(t.dropoff_datetime) AS dropoff_day,\n",
        "  hour(t.dropoff_datetime) AS dropoff_hour,\n",
        "  minute(t.dropoff_datetime) AS dropoff_minute,\n",
        "  second(t.dropoff_datetime) AS dropoff_second,\n",
        "  date(t.dropoff_datetime) AS dropoff_date,\n",
        "  unix_millis(t.pickup_datetime) as partition_id\n",
        "FROM \n",
        "  `synapse_nyc_reference`.`nyctaxi`.yellow_taxi_trips_raw t\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.vendor_lookup v\n",
        "    ON (t.vendor_id = v.vendor_id)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.trip_month_lookup tm\n",
        "    ON (t.trip_month = tm.trip_month)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.payment_type_lookup pt\n",
        "    ON (t.payment_type = pt.payment_type)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.rate_code_lookup rc\n",
        "    ON (t.rate_code_id = rc.rate_code_id)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzpu\n",
        "    ON (t.pickup_location_id = tzpu.location_id)\n",
        "  LEFT OUTER JOIN `synapse_nyc_reference`.`nyctaxi`.taxi_zone_lookup tzdo\n",
        "    ON (t.dropoff_location_id = tzdo.location_id)\n",
        "WHERE\n",
        "  t.trip_year >= 2015\n",
        "\"\"\"\n",
        "\n",
        "partition_sql_table = \"\"\"\n",
        "SELECT unix_millis(t.pickup_datetime) as partition_id FROM `synapse_nyc_reference`.`nyctaxi`.`yellow_taxi_trips_raw` t\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "curatedDF = optimized_jdbc_read(\n",
        "    sql=yellow_taxi_transform_sql,\n",
        "    table=partition_sql_table,\n",
        "    partition_filter=\"\",\n",
        "    partition_column=\"partition_id\",\n",
        "    num_partitions=4000\n",
        ").cache()\n",
        "\n",
        "curatedDF.count()\n",
        "\n",
        "# # Persist the final DataFrame with an optimized storage level\n",
        "# # This helps avoid recomputation and reduces shuffling in subsequent operations\n",
        "# from pyspark.storagelevel import StorageLevel\n",
        "# curatedDF = curatedDF.persist(StorageLevel.MEMORY_ONLY)\n",
        "\n",
        "curatedDFConformed = (curatedDF.withColumn(\"temp_vendor_id\", col(\"vendor_id\").cast(\"integer\")).drop(\"vendor_id\").withColumnRenamed(\"temp_vendor_id\", \"vendor_id\").withColumn(\"temp_payment_type\", col(\"payment_type\").cast(\"integer\")).drop(\"payment_type\").withColumnRenamed(\"temp_payment_type\", \"payment_type\"))\n",
        "dbutils.fs.rm(destDataDirRoot,recurse=True)\n",
        "curatedDFConformed.write.format(\"delta\").mode(\"overwrite\").partitionBy(\"trip_year\",\"trip_month\").save(destDataDirRoot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc335b47",
      "metadata": {},
      "outputs": [],
      "source": [
        "curatedDF.explain(True)  # Shows the execution plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.  Define external table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4289e51",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_table(schema: str, table_name: str, parquet_dir: str, location: str):\n",
        "    spark.sql(f\"use {schema};\")\n",
        "    spark.sql(f\"DROP TABLE IF EXISTS {table_name};\")\n",
        "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} USING delta LOCATION '{location}/{parquet_dir}';\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7219f082",
      "metadata": {},
      "outputs": [],
      "source": [
        "create_table(schema=\"synapse_nyc_reference.nyctaxi\", table_name=\"yellow_taxi_trips_transform\", parquet_dir=\"\", location=destDataDirRoot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.  Explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%sql\n",
        "select count(*) as trip_count from taxi_db.yellow_taxi_trips_curated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%sql\n",
        "select trip_year,trip_month, count(*) as trip_count from taxi_db.yellow_taxi_trips_curated group by trip_year,trip_month"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "TransformDataYellowTaxi",
      "notebookOrigID": 0,
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
